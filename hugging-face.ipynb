{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Update 2\n",
    "\n",
    "Second update for Cases Study project, this update focuses on following suggestions and showing progress with the last next steps we had in the previous update.\n",
    "\n",
    "## Pending tasks\n",
    "\n",
    "From the previous update the pending tasks were:\n",
    "\n",
    "1. Classify more tweets: We were able to download more tweets from the tweeter API, but we are still short with the manual classification, as we prioritized using the transformers library which already has some neat pre-trained models.\n",
    "\n",
    "2. Run an SVM classifier for the tweets: The SVM classifier was not trained or executed on its own, as we believe it's better to invest time in the actual problem that we want to solve, that is to show the sentiment analysis related to airlines in an easier and more meaningful way through dashboards.\n",
    "\n",
    "3. First dashboard displaying the collected data: We were able to put a dashboard together with the new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required SetUp\n",
    "\n",
    "The following setup is needed to install the transformers library, only macOS instructions are available at the moment.\n",
    "\n",
    "### macOS\n",
    "\n",
    "Installs the Rust compiler to build the tokenizers library\n",
    "\n",
    "```shell\n",
    "brew install rustup-init\n",
    "```\n",
    "\n",
    "Add new env config to zshrc or equivalent\n",
    "\n",
    "```shell\n",
    "echo \"source ~/.cargo/env\" >> ~/.zshrc\n",
    "```\n",
    "\n",
    "_Source: [Installation Error - Failed building wheel for tokenizers](https://github.com/huggingface/transformers/issues/2831#issuecomment-1001437376)_\n",
    "\n",
    "Install tensorflow in macOS by following the [official Apple documentation](https://developer.apple.com/metal/tensorflow-plugin/)[1].\n",
    "\n",
    "Finish by installing the `transformers` library in the created virtual environment.\n",
    "\n",
    "Installs the transformers library for access to the models\n",
    "\n",
    "```shell\n",
    "pip install transformers\n",
    "```\n",
    "\n",
    "[1]: [Could not find a version that satisfies the requirement tensorflow](https://stackoverflow.com/questions/48720833/could-not-find-a-version-that-satisfies-the-requirement-tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardo@yalo.com/miniforge3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 18:49:38.196665: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-27 18:49:38.196806: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9996980428695679}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')\n",
    "classifier('We are very happy to introduce pipeline to the transformers repository.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wit the above classification of a sample message obtained from the hugging face site, we have successfully configured the classifier to run the model against the available twits we have. \n",
    "\n",
    "Below some of the available tweets in the original data set are ran through the model to test it with data now scoped to the domain of airlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tweets = pd.read_csv('../../archive/Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = old_tweets.iloc[0, ]\n",
    "tfm_result = classifier(row.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8633630275726318}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original confidence 1.000000 vs 0.863363\n",
      "Original label neutral vs new label positive\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original confidence %f vs %f\" % (row.airline_sentiment_confidence, tfm_result[0]['score']))\n",
    "\n",
    "print (\"Original label %s vs new label %s\" % (row.airline_sentiment, tfm_result[0]['label'].lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now possible to compare the previous and new labels to check how those may change by using the transformers model vs what the existing labeled data already has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in old_tweets.sample(n=10).iterrows():\n",
    "    tfm_result = classifier(row.text)[0]\n",
    "    old_tweets.loc[index, 'tfm_classification'] = tfm_result['label']\n",
    "    old_tweets.loc[index, 'tfm_score'] = tfm_result['score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>tfm_classification</th>\n",
       "      <th>tfm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>570009743160254464</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>569911515106582528</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>568958107205783554</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>568454386617356291</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>569670671695011840</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.991647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>569132950006185985</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.997139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>567737625637687296</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.984052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8107</th>\n",
       "      <td>568782407698149376</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.687430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9960</th>\n",
       "      <td>569600720254541824</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086</th>\n",
       "      <td>569541291467522048</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "925    570009743160254464           neutral                        1.0000   \n",
       "1157   569911515106582528          negative                        1.0000   \n",
       "2680   568958107205783554          negative                        1.0000   \n",
       "3423   568454386617356291          negative                        1.0000   \n",
       "4877   569670671695011840           neutral                        0.6801   \n",
       "5409   569132950006185985          negative                        1.0000   \n",
       "6673   567737625637687296           neutral                        0.6619   \n",
       "8107   568782407698149376          positive                        1.0000   \n",
       "9960   569600720254541824          negative                        1.0000   \n",
       "10086  569541291467522048          negative                        1.0000   \n",
       "\n",
       "      tfm_classification  tfm_score  \n",
       "925             NEGATIVE   0.998697  \n",
       "1157            NEGATIVE   0.998926  \n",
       "2680            NEGATIVE   0.999817  \n",
       "3423            NEGATIVE   0.999613  \n",
       "4877            NEGATIVE   0.991647  \n",
       "5409            NEGATIVE   0.997139  \n",
       "6673            NEGATIVE   0.984052  \n",
       "8107            NEGATIVE   0.687430  \n",
       "9960            NEGATIVE   0.998992  \n",
       "10086           NEGATIVE   0.999313  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tweets[~old_tweets['tfm_classification'].isna()][['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence', 'tfm_classification', 'tfm_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default model in use is [`distilbert-base-uncased-finetuned-sst-2-english`](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english), as we can see above the model only has `POSITIVE` and `NEGATIVE` classifications, or at least with the above tests, there's no neutral classification, at least not with the sample above.\n",
    "\n",
    "Let's try now with one of the most downloaded models available at Hugging Face, the [`cardiffnlp/twitter-xlm-roberta-base-sentiment`](https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment) (XLM-Roberta model).\n",
    "\n",
    "The step below requires to have the `sentencepiece` package installed. The steps below were followed to make it run on a Mac.\n",
    "\n",
    "```shell\n",
    "brew install cmake\n",
    "wget https://files.pythonhosted.org/packages/aa/71/bb7d64dcd80a6506146397bca7310d5a8684f0f9ef035f03affb657f1aec/sentencepiece-0.1.96.tar.gz\n",
    "brew install pkgconfig\n",
    "pip -v install  sentencepiece-0.1.96.tar.gz\n",
    "```\n",
    "\n",
    "After the above steps, the kernel must be restarted for the model to load properly.\n",
    "\n",
    "_Sources followed:_\n",
    "* [Add Mac M1 Compatibility](https://github.com/google/sentencepiece/issues/608#issuecomment-1158367943)\n",
    "* [ValueError: Couldn't instantiate the backend tokenizer while loading model tokenizer #9750](https://github.com/huggingface/transformers/issues/9750#issuecomment-766862107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLMRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFXLMRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "cdiff_model = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in old_tweets[~old_tweets['tfm_classification'].isna()].iterrows():\n",
    "    rbt_result = cdiff_model(row.text)[0]\n",
    "    old_tweets.loc[index, 'roberta_classification'] = rbt_result['label']\n",
    "    old_tweets.loc[index, 'roberta_score'] = rbt_result['score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>tfm_classification</th>\n",
       "      <th>tfm_score</th>\n",
       "      <th>roberta_classification</th>\n",
       "      <th>roberta_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>570009743160254464</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998697</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.515928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>569911515106582528</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998926</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.925066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>568958107205783554</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.940675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>568454386617356291</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999613</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.941453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>569670671695011840</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.991647</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.655823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>569132950006185985</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.997139</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.837570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>567737625637687296</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.984052</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.737134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8107</th>\n",
       "      <td>568782407698149376</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.687430</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.884003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9960</th>\n",
       "      <td>569600720254541824</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.839267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086</th>\n",
       "      <td>569541291467522048</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999313</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.941510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "925    570009743160254464           neutral                        1.0000   \n",
       "1157   569911515106582528          negative                        1.0000   \n",
       "2680   568958107205783554          negative                        1.0000   \n",
       "3423   568454386617356291          negative                        1.0000   \n",
       "4877   569670671695011840           neutral                        0.6801   \n",
       "5409   569132950006185985          negative                        1.0000   \n",
       "6673   567737625637687296           neutral                        0.6619   \n",
       "8107   568782407698149376          positive                        1.0000   \n",
       "9960   569600720254541824          negative                        1.0000   \n",
       "10086  569541291467522048          negative                        1.0000   \n",
       "\n",
       "      tfm_classification  tfm_score roberta_classification  roberta_score  \n",
       "925             NEGATIVE   0.998697               Negative       0.515928  \n",
       "1157            NEGATIVE   0.998926               Negative       0.925066  \n",
       "2680            NEGATIVE   0.999817               Negative       0.940675  \n",
       "3423            NEGATIVE   0.999613               Negative       0.941453  \n",
       "4877            NEGATIVE   0.991647                Neutral       0.655823  \n",
       "5409            NEGATIVE   0.997139               Negative       0.837570  \n",
       "6673            NEGATIVE   0.984052                Neutral       0.737134  \n",
       "8107            NEGATIVE   0.687430               Positive       0.884003  \n",
       "9960            NEGATIVE   0.998992               Negative       0.839267  \n",
       "10086           NEGATIVE   0.999313               Negative       0.941510  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tweets[~old_tweets['tfm_classification'].isna()][['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence', 'tfm_classification', 'tfm_score', 'roberta_classification', 'roberta_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to see how the XLM-Roberta model closely matches the manually classified tweets above, more specifically the neutral tweets, which could not be obtained directly from the first model we tried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on fresh tweets\n",
    "\n",
    "Below some sample tweets are obtained from the Twitter API to run them through the classifier.\n",
    "\n",
    "From the original data we can check which airlines are available to get an idea of how we should retrieve data from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United</td>\n",
       "      <td>3822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US Airways</td>\n",
       "      <td>2913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American</td>\n",
       "      <td>2759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>2420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delta</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          airline  tweet_id\n",
       "4          United      3822\n",
       "3      US Airways      2913\n",
       "0        American      2759\n",
       "2       Southwest      2420\n",
       "1           Delta      2222\n",
       "5  Virgin America       504"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tweets[['airline', 'tweet_id']].groupby('airline', as_index=False).count().sort_values('tweet_id', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code from this section onwards requries the [`searchtweets-v2`](https://pypi.org/project/searchtweets-v2/) library. Make sure to have it installed in your env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searchtweets import ResultStream, gen_request_parameters, load_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_args = load_credentials(\"./.twitter_keys.yaml\", yaml_key=\"search_tweets_v2\",env_overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\": \"@United\", \"max_results\": 10, \"tweet.fields\": \"created_at\"}\n"
     ]
    }
   ],
   "source": [
    "query = gen_request_parameters(\"@United\", results_per_call=10, granularity=None, tweet_fields='created_at')\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ResultStream(request_parameters=query, max_results=10, max_pages=1, **search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = list(rs.stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'created_at': '2022-07-07T22:28:20.000Z',\n",
       "   'id': '1545172895369859072',\n",
       "   'text': 'RT @IBJIYONGI: So the universe is making up for the scary landing situation ‚Äî if you‚Äôre in the @united terminal at SFO, stop by Compass Boo‚Ä¶'},\n",
       "  {'created_at': '2022-07-07T22:27:27.000Z',\n",
       "   'id': '1545172673135017984',\n",
       "   'text': 'RT @Angels: Baltimore ‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è!!!\\n\\n‚úàÔ∏è x @united https://t.co/czqn63jebQ'},\n",
       "  {'created_at': '2022-07-07T22:25:17.000Z',\n",
       "   'id': '1545172126403026946',\n",
       "   'text': \"RT @united: Good things come to those who don't wait. Download the United app to save time at the airport.\"},\n",
       "  {'created_at': '2022-07-07T22:23:36.000Z',\n",
       "   'id': '1545171700840632323',\n",
       "   'text': 'RT @HuffmanLabDU: 13/ Interesting that @United reworked standard flight attendant speech to announce proud use of ‚Äúantimicrobial surfaces,‚Äù‚Ä¶'},\n",
       "  {'created_at': '2022-07-07T22:22:25.000Z',\n",
       "   'id': '1545171403439108096',\n",
       "   'text': '@RyanPaevey @united Were you there when the plane was built? No? Late! :P'},\n",
       "  {'created_at': '2022-07-07T22:20:54.000Z',\n",
       "   'id': '1545171023204683781',\n",
       "   'text': 'Looking to exchange some free laughs or jokes for two (2) @united Club day passes for this Saturday evening. \\n\\nTopics of jokes or laughs are negotiable.'},\n",
       "  {'created_at': '2022-07-07T22:20:51.000Z',\n",
       "   'id': '1545171010793586688',\n",
       "   'text': '@united How much? 10,000 dollars?'},\n",
       "  {'created_at': '2022-07-07T22:18:01.000Z',\n",
       "   'id': '1545170296122101762',\n",
       "   'text': '@907FLY @ChocoMeditator @united \"You don\\'t understand how masks work\"\\nBruh, I bet $50 you don\\'t understand how viral load affects transmission or symptom severity\\nI bet you think in all or nothing terms and it shows'},\n",
       "  {'created_at': '2022-07-07T22:17:27.000Z',\n",
       "   'id': '1545170156267118594',\n",
       "   'text': '@united @wilsonography @united Why?  Why do you say boarding begins at 5:54, for it to be 6:15pm and the boarding hasn‚Äôt started yet?  What‚Äôs the point of having an app if the info in it is not correct?  1190'},\n",
       "  {'created_at': '2022-07-07T22:16:11.000Z',\n",
       "   'id': '1545169837978173440',\n",
       "   'text': '@united Why?  Why do you say boarding begins at 5:54, for it to be 6:15pm and the boarding hasn‚Äôt started yet?  What‚Äôs the point of having an app if the info in it is not correct?'}],\n",
       " 'meta': {'newest_id': '1545172895369859072',\n",
       "  'oldest_id': '1545169837978173440',\n",
       "  'result_count': 10,\n",
       "  'next_token': 'b26v89c19zqg8o3fpz2mg0lm6n2zyb2foephef68slj7h'}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the above in a nicer way by creating a data frame from the data obtained. We can see that the response has all the tweets inside a `data` field, that can be merged into a single list, which will be used to then load a data frame with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "united_sample = []\n",
    "for tg in tweets:\n",
    "    united_sample.extend(tg['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "united_sample_df = pd.DataFrame(united_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-07T22:58:31.000Z</td>\n",
       "      <td>1545180489790529536</td>\n",
       "      <td>@jonathangooda @Cheryl_Searle @carolyn_mcglynn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-07T22:57:41.000Z</td>\n",
       "      <td>1545180281300307968</td>\n",
       "      <td>@DocReggies @tkausiyo @united Sadly abva afa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-07T22:57:19.000Z</td>\n",
       "      <td>1545180188484554754</td>\n",
       "      <td>@RyanPaevey @united Happened to me too once on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-07T22:55:13.000Z</td>\n",
       "      <td>1545179659746304005</td>\n",
       "      <td>@tkausiyo @TapiwaMunjoma @united ü§£ü§£ü§£</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-07T22:53:04.000Z</td>\n",
       "      <td>1545179118639099904</td>\n",
       "      <td>@united What are United‚Äôs stats against a peer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2022-07-07T16:00:56.000Z</td>\n",
       "      <td>1545075402158137345</td>\n",
       "      <td>@Shrekgotthepha1 @united Some bih eating what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2022-07-07T16:00:08.000Z</td>\n",
       "      <td>1545075201909690370</td>\n",
       "      <td>@haleysnothere21 @united RT full eyes trueblue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2022-07-07T15:59:50.000Z</td>\n",
       "      <td>1545075124533182467</td>\n",
       "      <td>@united screen won‚Äôt let me add another travel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2022-07-07T15:57:56.000Z</td>\n",
       "      <td>1545074645367263234</td>\n",
       "      <td>@sell_arte_sell @Angels @united Buses were full.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2022-07-07T15:56:22.000Z</td>\n",
       "      <td>1545074251593486336</td>\n",
       "      <td>@united I‚Äôm still waiting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   created_at                   id  \\\n",
       "0    2022-07-07T22:58:31.000Z  1545180489790529536   \n",
       "1    2022-07-07T22:57:41.000Z  1545180281300307968   \n",
       "2    2022-07-07T22:57:19.000Z  1545180188484554754   \n",
       "3    2022-07-07T22:55:13.000Z  1545179659746304005   \n",
       "4    2022-07-07T22:53:04.000Z  1545179118639099904   \n",
       "..                        ...                  ...   \n",
       "495  2022-07-07T16:00:56.000Z  1545075402158137345   \n",
       "496  2022-07-07T16:00:08.000Z  1545075201909690370   \n",
       "497  2022-07-07T15:59:50.000Z  1545075124533182467   \n",
       "498  2022-07-07T15:57:56.000Z  1545074645367263234   \n",
       "499  2022-07-07T15:56:22.000Z  1545074251593486336   \n",
       "\n",
       "                                                  text  \n",
       "0    @jonathangooda @Cheryl_Searle @carolyn_mcglynn...  \n",
       "1        @DocReggies @tkausiyo @united Sadly abva afa.  \n",
       "2    @RyanPaevey @united Happened to me too once on...  \n",
       "3                 @tkausiyo @TapiwaMunjoma @united ü§£ü§£ü§£  \n",
       "4    @united What are United‚Äôs stats against a peer...  \n",
       "..                                                 ...  \n",
       "495  @Shrekgotthepha1 @united Some bih eating what ...  \n",
       "496  @haleysnothere21 @united RT full eyes trueblue...  \n",
       "497  @united screen won‚Äôt let me add another travel...  \n",
       "498   @sell_arte_sell @Angels @united Buses were full.  \n",
       "499                          @united I‚Äôm still waiting  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "united_sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving them for posterity, to prevent us from having to query the API again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# united_sample_df.to_csv('./fresh_data/united_sample_070722.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run it through the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roberta_classifies(df, classifier=cdiff_model):\n",
    "    classification_times = []\n",
    "    for index, row in df.iterrows():\n",
    "        start_time = time.time()\n",
    "        \n",
    "        rbt_result = classifier(row.text)[0]\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        classification_times.append(end_time-start_time)\n",
    "        \n",
    "        df.loc[index, 'classification'] = rbt_result['label']\n",
    "        df.loc[index, 'score'] = rbt_result['score']\n",
    "\n",
    "    return classification_times, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_classifies(united_sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-07T22:58:31.000Z</td>\n",
       "      <td>1545180489790529536</td>\n",
       "      <td>@jonathangooda @Cheryl_Searle @carolyn_mcglynn...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.676336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-07T22:57:41.000Z</td>\n",
       "      <td>1545180281300307968</td>\n",
       "      <td>@DocReggies @tkausiyo @united Sadly abva afa.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.879338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-07T22:57:19.000Z</td>\n",
       "      <td>1545180188484554754</td>\n",
       "      <td>@RyanPaevey @united Happened to me too once on...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.825423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-07T22:55:13.000Z</td>\n",
       "      <td>1545179659746304005</td>\n",
       "      <td>@tkausiyo @TapiwaMunjoma @united ü§£ü§£ü§£</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.544360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-07T22:53:04.000Z</td>\n",
       "      <td>1545179118639099904</td>\n",
       "      <td>@united What are United‚Äôs stats against a peer...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.948139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2022-07-07T16:00:56.000Z</td>\n",
       "      <td>1545075402158137345</td>\n",
       "      <td>@Shrekgotthepha1 @united Some bih eating what ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.951184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2022-07-07T16:00:08.000Z</td>\n",
       "      <td>1545075201909690370</td>\n",
       "      <td>@haleysnothere21 @united RT full eyes trueblue...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.439411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2022-07-07T15:59:50.000Z</td>\n",
       "      <td>1545075124533182467</td>\n",
       "      <td>@united screen won‚Äôt let me add another travel...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.769451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2022-07-07T15:57:56.000Z</td>\n",
       "      <td>1545074645367263234</td>\n",
       "      <td>@sell_arte_sell @Angels @united Buses were full.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.486825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2022-07-07T15:56:22.000Z</td>\n",
       "      <td>1545074251593486336</td>\n",
       "      <td>@united I‚Äôm still waiting</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.627610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   created_at                   id  \\\n",
       "0    2022-07-07T22:58:31.000Z  1545180489790529536   \n",
       "1    2022-07-07T22:57:41.000Z  1545180281300307968   \n",
       "2    2022-07-07T22:57:19.000Z  1545180188484554754   \n",
       "3    2022-07-07T22:55:13.000Z  1545179659746304005   \n",
       "4    2022-07-07T22:53:04.000Z  1545179118639099904   \n",
       "..                        ...                  ...   \n",
       "495  2022-07-07T16:00:56.000Z  1545075402158137345   \n",
       "496  2022-07-07T16:00:08.000Z  1545075201909690370   \n",
       "497  2022-07-07T15:59:50.000Z  1545075124533182467   \n",
       "498  2022-07-07T15:57:56.000Z  1545074645367263234   \n",
       "499  2022-07-07T15:56:22.000Z  1545074251593486336   \n",
       "\n",
       "                                                  text classification  \\\n",
       "0    @jonathangooda @Cheryl_Searle @carolyn_mcglynn...        Neutral   \n",
       "1        @DocReggies @tkausiyo @united Sadly abva afa.       Negative   \n",
       "2    @RyanPaevey @united Happened to me too once on...       Negative   \n",
       "3                 @tkausiyo @TapiwaMunjoma @united ü§£ü§£ü§£        Neutral   \n",
       "4    @united What are United‚Äôs stats against a peer...       Negative   \n",
       "..                                                 ...            ...   \n",
       "495  @Shrekgotthepha1 @united Some bih eating what ...       Negative   \n",
       "496  @haleysnothere21 @united RT full eyes trueblue...        Neutral   \n",
       "497  @united screen won‚Äôt let me add another travel...       Negative   \n",
       "498   @sell_arte_sell @Angels @united Buses were full.        Neutral   \n",
       "499                          @united I‚Äôm still waiting        Neutral   \n",
       "\n",
       "        score  \n",
       "0    0.676336  \n",
       "1    0.879338  \n",
       "2    0.825423  \n",
       "3    0.544360  \n",
       "4    0.948139  \n",
       "..        ...  \n",
       "495  0.951184  \n",
       "496  0.439411  \n",
       "497  0.769451  \n",
       "498  0.486825  \n",
       "499  0.627610  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "united_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classification   id\n",
       "0       Negative  224\n",
       "1        Neutral  148\n",
       "2       Positive  128"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "united_sample_df[['id', 'classification']].groupby('classification', as_index=False).count().sort_values('id', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_by_label(df, label: str, score=0.8):\n",
    "    with pd.option_context('display.max_colwidth', None):\n",
    "        display(df.loc[(df['score'] > score) & (df['classification'] == label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-07T22:57:41.000Z</td>\n",
       "      <td>1545180281300307968</td>\n",
       "      <td>@DocReggies @tkausiyo @united Sadly abva afa.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.879338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-07T22:57:19.000Z</td>\n",
       "      <td>1545180188484554754</td>\n",
       "      <td>@RyanPaevey @united Happened to me too once on my return ‚úàÔ∏è from Johannesburg. I did pre check in,arrived +3 hrs early. I got bumped; agent told me he couldn‚Äôt check in my bag yet,to step aside while he checked in other passengers?!!üò° No explanation. I lost myüí©üò§.I spoke to manager &amp;amp; got on my‚úàÔ∏èüòä</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.825423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-07T22:53:04.000Z</td>\n",
       "      <td>1545179118639099904</td>\n",
       "      <td>@united What are United‚Äôs stats against a peer, like Delta, instead of a low cost carrier, in a comparable market like NYC? EWR, LGA, JFK. Comparing yourself to Southwest seems to be a disservice to United.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.948139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-07-07T22:44:56.000Z</td>\n",
       "      <td>1545177070992445441</td>\n",
       "      <td>@BaconGrillin123 @united It wasn't. @united has terrible customer service =)</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.861602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-07-07T22:35:12.000Z</td>\n",
       "      <td>1545174619946090497</td>\n",
       "      <td>@KatLaRonde @united @united Why?  Why do you say boarding begins at 5:54, for it to be 6:35 and the boarding hasn‚Äôt started yet?  What‚Äôs the point of having an app if the info in it is not correct? 1190</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.815759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2022-07-07T16:23:29.000Z</td>\n",
       "      <td>1545081075247919105</td>\n",
       "      <td>RT @VeronicaSam13: I told y'all so! This is a concerted effort to embarrass Biden's FAA appointee and Buttgieg!!\\nWe see you @united !! http‚Ä¶</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.915078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2022-07-07T16:22:14.000Z</td>\n",
       "      <td>1545080760360734720</td>\n",
       "      <td>@united Wade through fecal matter and needles in craphole SF to get to your new destination of covid concentration camps? So tempting but that is a hard pass for me.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.884115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2022-07-07T16:11:21.000Z</td>\n",
       "      <td>1545078023547912192</td>\n",
       "      <td>@united #unitedairlines \\n\\nI have called and message United for maybe over 5 hours worth of time. The file ref number given by United is too many digits to fit on your claims page. Why is this so hard?</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.882415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>2022-07-07T16:01:34.000Z</td>\n",
       "      <td>1545075559897747456</td>\n",
       "      <td>@united worst experience in an airport or with airlines ever! Almost 9 hours of continuous delays only to cancel flight. No vouchers or food offered until flight was being canceled. Every answer vague and intentionally misleading. After 16 hours we finally were able to fly</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.953092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2022-07-07T16:00:56.000Z</td>\n",
       "      <td>1545075402158137345</td>\n",
       "      <td>@Shrekgotthepha1 @united Some bih eating what smells like salami near me its so foul</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.951184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   created_at                   id  \\\n",
       "1    2022-07-07T22:57:41.000Z  1545180281300307968   \n",
       "2    2022-07-07T22:57:19.000Z  1545180188484554754   \n",
       "4    2022-07-07T22:53:04.000Z  1545179118639099904   \n",
       "7    2022-07-07T22:44:56.000Z  1545177070992445441   \n",
       "13   2022-07-07T22:35:12.000Z  1545174619946090497   \n",
       "..                        ...                  ...   \n",
       "473  2022-07-07T16:23:29.000Z  1545081075247919105   \n",
       "475  2022-07-07T16:22:14.000Z  1545080760360734720   \n",
       "483  2022-07-07T16:11:21.000Z  1545078023547912192   \n",
       "494  2022-07-07T16:01:34.000Z  1545075559897747456   \n",
       "495  2022-07-07T16:00:56.000Z  1545075402158137345   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                             text  \\\n",
       "1                                                                                                                                                                                                                                                                   @DocReggies @tkausiyo @united Sadly abva afa.   \n",
       "2    @RyanPaevey @united Happened to me too once on my return ‚úàÔ∏è from Johannesburg. I did pre check in,arrived +3 hrs early. I got bumped; agent told me he couldn‚Äôt check in my bag yet,to step aside while he checked in other passengers?!!üò° No explanation. I lost myüí©üò§.I spoke to manager &amp; got on my‚úàÔ∏èüòä   \n",
       "4                                                                                                  @united What are United‚Äôs stats against a peer, like Delta, instead of a low cost carrier, in a comparable market like NYC? EWR, LGA, JFK. Comparing yourself to Southwest seems to be a disservice to United.   \n",
       "7                                                                                                                                                                                                                                    @BaconGrillin123 @united It wasn't. @united has terrible customer service =)   \n",
       "13                                                                                                     @KatLaRonde @united @united Why?  Why do you say boarding begins at 5:54, for it to be 6:35 and the boarding hasn‚Äôt started yet?  What‚Äôs the point of having an app if the info in it is not correct? 1190   \n",
       "..                                                                                                                                                                                                                                                                                                            ...   \n",
       "473                                                                                                                                                                 RT @VeronicaSam13: I told y'all so! This is a concerted effort to embarrass Biden's FAA appointee and Buttgieg!!\\nWe see you @united !! http‚Ä¶   \n",
       "475                                                                                                                                         @united Wade through fecal matter and needles in craphole SF to get to your new destination of covid concentration camps? So tempting but that is a hard pass for me.   \n",
       "483                                                                                                    @united #unitedairlines \\n\\nI have called and message United for maybe over 5 hours worth of time. The file ref number given by United is too many digits to fit on your claims page. Why is this so hard?   \n",
       "494                             @united worst experience in an airport or with airlines ever! Almost 9 hours of continuous delays only to cancel flight. No vouchers or food offered until flight was being canceled. Every answer vague and intentionally misleading. After 16 hours we finally were able to fly   \n",
       "495                                                                                                                                                                                                                          @Shrekgotthepha1 @united Some bih eating what smells like salami near me its so foul   \n",
       "\n",
       "    classification     score  \n",
       "1         Negative  0.879338  \n",
       "2         Negative  0.825423  \n",
       "4         Negative  0.948139  \n",
       "7         Negative  0.861602  \n",
       "13        Negative  0.815759  \n",
       "..             ...       ...  \n",
       "473       Negative  0.915078  \n",
       "475       Negative  0.884115  \n",
       "483       Negative  0.882415  \n",
       "494       Negative  0.953092  \n",
       "495       Negative  0.951184  \n",
       "\n",
       "[126 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_by_label(united_sample_df, 'Negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, let's store our classified tweets, just to prevent us from loosing the data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# united_sample_df.to_csv('./classified_data/united_sample_070722_sa_classified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now generalize the tweets search to allow us to get more tweets as we need it.\n",
    "\n",
    "> ‚ö†Ô∏è For some reason, it looks like the twitter search v2 client is broken and is actually not returning the right format for the values, it should be directly returning the tweets, but it's not doing that and the returned payload is wrapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is usually only set once, although, it can change depending on the endpoint we want to reach, as defined in the yaml_key\n",
    "search_args = load_credentials(\"./.twitter_keys.yaml\", yaml_key=\"search_tweets_v2\",env_overwrite=False)\n",
    "\n",
    "def search_tweets(text_query: str, search_args, results_per_call=10, max_results=10):\n",
    "    \"\"\"\n",
    "    Returns a tweet stream for the provided text query, it can then be iterated to retrieve each individual tweet.\n",
    "    Args:\n",
    "        text_query (str): The topic of interest or text to search for.\n",
    "        search_args (dict): Arguments needed to authenticate.\n",
    "    Returns:\n",
    "        a result stream iterable/generator.\n",
    "    \"\"\"\n",
    "    query = gen_request_parameters(text_query, results_per_call=results_per_call, granularity=None, tweet_fields='created_at')\n",
    "    rs = ResultStream(request_parameters=query, max_results=max_results, max_pages=1, **search_args)\n",
    "    return rs.stream()\n",
    "\n",
    "def merge_stream_results(tweets):\n",
    "    sample = []\n",
    "    for tg in tweets:\n",
    "        sample.extend(tg['data'])\n",
    "\n",
    "    return pd.DataFrame(sample)\n",
    "\n",
    "def get_date_suffix():\n",
    "    now = datetime.now() \n",
    "    return now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "\n",
    "def get_fresh_classified_tweets(handlers: list, search_args: dict, *args):\n",
    "    for h in handlers:\n",
    "        print(f\"Getting fresh tweets for {h}...\")\n",
    "\n",
    "        tws_stream = search_tweets(f\"@{h}\", search_args, *args)\n",
    "\n",
    "        df = merge_stream_results(tws_stream)\n",
    "\n",
    "        f_suffix = get_date_suffix()\n",
    "\n",
    "        df.to_csv(f'./fresh_data/{h.lower()}_sample_{f_suffix}.csv')\n",
    "\n",
    "        c_times, df_class = roberta_classifies(df)\n",
    "\n",
    "        df_class.to_csv(f'./classified_data/{h.lower()}_sample_{f_suffix}_sa_classified.csv')\n",
    "\n",
    "        c_times_df = pd.DataFrame(c_times)\n",
    "\n",
    "        c_times_df.to_csv(f'./classification_times/{h.lower()}_{suffix}.csv', index=False)\n",
    "\n",
    "        print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below some of the top US and Canada airlines are considered for the retrieval of tweets. The original dataset was revised to remove those airlines no longer in operation due to merging or buyouts by other companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_tw_handlers = [\"United\", \"AmericanAir\", \"SouthwestAir\", \"Delta\", \"alaskaair\", \"AirCanada\", \"WestJet\", \"airtransat\", \"porterairlines\", \"FlairAirlines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting fresh tweets for alaskaair...\n",
      "Done!\n",
      "Getting fresh tweets for AirCanada...\n",
      "Done!\n",
      "Getting fresh tweets for WestJet...\n",
      "Done!\n",
      "Getting fresh tweets for airtransat...\n",
      "Done!\n",
      "Getting fresh tweets for porterairlines...\n",
      "Done!\n",
      "Getting fresh tweets for FlairAirlines...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "get_fresh_classified_tweets(airlines_tw_handlers[4:], search_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovery of results\n",
    "\n",
    "Loading and classifying intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = pd.read_csv('./fresh_data/americanair_sample_07072022.csv')\n",
    "\n",
    "c_time, df_class = roberta_classifies(df_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_times_df = pd.DataFrame(c_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAASKElEQVR4nO3cf6zddX3H8edbqo71AgWrN13pLFvKXKUT7Q0jc4n3zkURMwtqSBkqdbg6h5uLXWLVJRINGfuBZgZmVoVQf3FlqLHjhwt2vSGYNUq1UAoDq5RJZe3U8uMi0xXf++N8q8fLPT2/z7nns+cjObnf7+f7/Z7v65xz+7rffs8538hMJElledawA0iSes9yl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3KUGIuKUiPhiRDwZEQ9FxB8OO5PUqkXDDiAtYFcDPwHGgTOBmyPirszcO9RUUgvCb6hKzxQRi4HDwBmZ+UA19ingQGZuHmo4qQWelpHmdzpw5GixV+4CXjykPFJbLHdpfmPA43PGHgNOGEIWqW2WuzS/WeDEOWMnAk8MIYvUNstdmt8DwKKIWFU39hLAN1M1EnxDVWogIqaBBN5G7dMytwC/46dlNAo8cpca+1PgeOAQcD3wDotdo8Ijd0kqkEfuklQgy12SCmS5S1KBLHdJKtCCuHDY0qVLc+XKlQPb35NPPsnixYsHtr9OjULOUcgI5uy1Ucg5Chmhu5y7du36fmY+f96FmTn029q1a3OQduzYMdD9dWoUco5Cxkxz9too5ByFjJnd5QTuzAa92vS0TESsiIgdEXFvROyNiHdV45dFxIGI2F3dzq3b5r0RsS8i7o+IV3f0J0mS1LFWTsscATZl5jci4gRgV0TcVi37SGb+ff3KEbEaWE/t6nm/AnwlIk7PzKd7GVyS1FjTI/fMfCQzv1FNPwHcByw/xibrgOnM/HFmPgjsA87qRVhJUmva+oZqRKwEbgfOAN4NbKB2WdQ7qR3dH46Iq4CdmfnpaptrgFsz88Y597UR2AgwPj6+dnp6uusH06rZ2VnGxsYGtr9OjULOUcgI5uy1Ucg5Chmhu5xTU1O7MnNi3oWNTsbPvVG7vvUu4PXV/DhwHLWj/8uBa6vxq4A31W13DfDGY923b6jObxRyjkLGTHP22ijkHIWMmUN8QxUgIp4NfB74TGZ+ofqjcDAzn87MnwIf5+enXg4AK+o2P7UakyQNSCuflglqR9/3ZeaH68aX1a12PnBPNb0NWB8Rz42I04BVwNd6F1mS1Ewrn5Z5OfBmYE9E7K7G3gdcGBFnUrve9X7g7QCZuTcibgDupfZJm0vTT8pI0kA1LffMvAOIeRbdcoxtLqd2Hl6SNAQL4vID3Vi5+ea2t9m05ggbOthurv1XvLbr+5CkfvDCYZJUIMtdkgo08qdlhqmTU0LtaHT6yNNBkprxyF2SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUBNyz0iVkTEjoi4NyL2RsS7qvFTIuK2iPhW9fPkajwi4qMRsS8i7o6Il/X7QUiSflErR+5HgE2ZuRo4G7g0IlYDm4HtmbkK2F7NA7wGWFXdNgIf63lqSdIxNS33zHwkM79RTT8B3AcsB9YBW6vVtgLnVdPrgE9mzU5gSUQs63VwSVJjkZmtrxyxErgdOAP4z8xcUo0HcDgzl0TETcAVmXlHtWw78J7MvHPOfW2kdmTP+Pj42unp6Y4ewJ4Dj7W9zfjxcPCpjnY3UI1yrll+0uDDNDA7O8vY2NiwYzRlzt4ahZyjkBG6yzk1NbUrMyfmW7ao1TuJiDHg88BfZObjtT6vycyMiNb/StS22QJsAZiYmMjJycl2Nv+ZDZtvbnubTWuOcOWelh/60DTKuf+iycGHaWBmZoZOX7tBMmdvjULOUcgI/cvZ0qdlIuLZ1Ir9M5n5hWr44NHTLdXPQ9X4AWBF3eanVmOSpAFp5dMyAVwD3JeZH65btA24uJq+GPhS3fhbqk/NnA08lpmP9DCzJKmJVs5NvBx4M7AnInZXY+8DrgBuiIhLgIeAC6pltwDnAvuAHwFv7WVgSVJzTcu9emM0Gix+5TzrJ3Bpl7kkSV3wG6qSVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCtS03CPi2og4FBH31I1dFhEHImJ3dTu3btl7I2JfRNwfEa/uV3BJUmOtHLlfB5wzz/hHMvPM6nYLQESsBtYDL662+ceIOK5XYSVJrWla7pl5O/DDFu9vHTCdmT/OzAeBfcBZXeSTJHUgMrP5ShErgZsy84xq/jJgA/A4cCewKTMPR8RVwM7M/HS13jXArZl54zz3uRHYCDA+Pr52enq6owew58BjbW8zfjwcfKqj3Q1Uo5xrlp80+DANzM7OMjY2NuwYTZmzt0Yh5yhkhO5yTk1N7crMifmWLeowz8eADwFZ/bwS+KN27iAztwBbACYmJnJycrKjIBs239z2NpvWHOHKPZ0+9MFplHP/RZODD9PAzMwMnb52g2TO3hqFnKOQEfqXs6NPy2Tmwcx8OjN/Cnycn596OQCsqFv11GpMkjRAHZV7RCyrmz0fOPpJmm3A+oh4bkScBqwCvtZdRElSu5qem4iI64FJYGlEPAx8AJiMiDOpnZbZD7wdIDP3RsQNwL3AEeDSzHy6L8klSQ01LffMvHCe4WuOsf7lwOXdhJIkdcdvqEpSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoGalntEXBsRhyLinrqxUyLitoj4VvXz5Go8IuKjEbEvIu6OiJf1M7wkaX6tHLlfB5wzZ2wzsD0zVwHbq3mA1wCrqttG4GO9iSlJakfTcs/M24EfzhleB2ytprcC59WNfzJrdgJLImJZj7JKklrU6Tn38cx8pJr+L2C8ml4OfLduvYerMUnSAEVmNl8pYiVwU2aeUc0/mplL6pYfzsyTI+Im4IrMvKMa3w68JzPvnOc+N1I7dcP4+Pja6enpjh7AngOPtb3N+PFw8KmOdjdQjXKuWX7S4MM0MDs7y9jY2LBjNGXO3hqFnKOQEbrLOTU1tSszJ+ZbtqjDPAcjYllmPlKddjlUjR8AVtStd2o19gyZuQXYAjAxMZGTk5MdBdmw+ea2t9m05ghX7un0oQ9Oo5z7L5ocfJgGZmZm6PS1GyRz9tYo5ByFjNC/nJ2eltkGXFxNXwx8qW78LdWnZs4GHqs7fSNJGpCmh68RcT0wCSyNiIeBDwBXADdExCXAQ8AF1eq3AOcC+4AfAW/tQ2ZJUhNNyz0zL2yw6JXzrJvApd2GkiR1x2+oSlKBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSrQom42joj9wBPA08CRzJyIiFOAzwErgf3ABZl5uLuYkqR29OLIfSozz8zMiWp+M7A9M1cB26t5SdIA9eO0zDpgazW9FTivD/uQJB1DZGbnG0c8CBwGEvinzNwSEY9m5pJqeQCHj87P2XYjsBFgfHx87fT0dEcZ9hx4rO1txo+Hg091tLuBapRzzfKTBh+mgdnZWcbGxoYdoylz9tYo5ByFjNBdzqmpqV11Z01+QVfn3IHfzcwDEfEC4LaI+I/6hZmZETHvX4/M3AJsAZiYmMjJycmOAmzYfHPb22xac4Qr93T70PuvUc79F00OPkwDMzMzdPraDZI5e2sUco5CRuhfzq5Oy2TmgernIeCLwFnAwYhYBlD9PNRtSElSezou94hYHBEnHJ0GXgXcA2wDLq5Wuxj4UrchJUnt6ebcxDjwxdppdRYBn83ML0fE14EbIuIS4CHggu5jSpLa0XG5Z+Z3gJfMM/4D4JXdhJIkdcdvqEpSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVaNGwA6h9KzffPLR977/itUPbt6TWeeQuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUBefkBtmXvpg01rjrBhAJdD8LIHUns8cpekAvWt3CPinIi4PyL2RcTmfu1HkvRMfSn3iDgOuBp4DbAauDAiVvdjX5KkZ+rXOfezgH2Z+R2AiJgG1gH39ml/ktSxYV5G+7pzFvflfiMze3+nEW8EzsnMt1XzbwZ+OzPfWbfORmBjNfsbwP09D9LYUuD7A9xfp0Yh5yhkBHP22ijkHIWM0F3OF2bm8+dbMLRPy2TmFmDLMPYdEXdm5sQw9t2OUcg5ChnBnL02CjlHISP0L2e/3lA9AKyomz+1GpMkDUC/yv3rwKqIOC0ingOsB7b1aV+SpDn6clomM49ExDuBfwWOA67NzL392FeHhnI6qAOjkHMUMoI5e20Uco5CRuhTzr68oSpJGi6/oSpJBbLcJalARZd7s0sgRMS7I+LeiLg7IrZHxAsXYMY/iYg9EbE7Iu4Y1jd9W72cRES8ISIyIobyEbQWns8NEfHf1fO5OyLethBzVutcUP1+7o2Izy60jBHxkbrn8YGIeHTQGasczXL+akTsiIhvVv/Wz12gOV9Y9dDdETETEad2tcPMLPJG7Y3cbwO/BjwHuAtYPWedKeCXq+l3AJ9bgBlPrJt+HfDlhfhcVuudANwO7AQmFmJOYANw1TB+J9vMuQr4JnByNf+ChZZxzvp/Ru2DEwvxudwCvKOaXg3sX6A5/xm4uJr+PeBT3eyz5CP3n10CITN/Ahy9BMLPZOaOzPxRNbuT2ufxF1rGx+tmFwPDeAe8ac7Kh4C/Af5nkOHqtJpz2FrJ+cfA1Zl5GCAzDy3AjPUuBK4fSLJf1ErOBE6spk8CvjfAfEe1knM18G/V9I55lrel5HJfDny3bv7haqyRS4Bb+5romVrKGBGXRsS3gb8F/nxA2eo1zRkRLwNWZObwLtLR+mv+huq/vjdGxIp5lvdbKzlPB06PiK9GxM6IOGdg6Wpa/vdTnc48jZ8X0yC1kvMy4E0R8TBwC7X/ZQxaKznvAl5fTZ8PnBARz+t0hyWXe8si4k3ABPB3w84yn8y8OjN/HXgP8FfDzjNXRDwL+DCwadhZWvAvwMrM/C3gNmDrkPM0sojaqZlJakfFH4+IJcMMdAzrgRsz8+lhB2ngQuC6zDwVOBf4VPU7u9D8JfCKiPgm8Apq3+rv+DldiA+wV1q6BEJE/D7wfuB1mfnjAWU7qt3LNEwD5/UzUAPNcp4AnAHMRMR+4Gxg2xDeVG36fGbmD+pe508AaweUrV4rr/vDwLbM/N/MfBB4gFrZD0o7v5vrGc4pGWgt5yXADQCZ+e/AL1G7WNcgtfK7+b3MfH1mvpRaJ5GZj3a8x0G/sTDANzAWAd+h9t/Fo29gvHjOOi+l9ibHqgWccVXd9B8Ady7EnHPWn2E4b6i28nwuq5s+H9i5QHOeA2ytppdS+y/98xZSxmq9FwH7qb4QuUCfy1uBDdX0b1I75z7QvC3mXAo8q5q+HPhgV/scxgsywCf0XGpHPN8G3l+NfZDaUTrAV4CDwO7qtm0BZvwHYG+Vb8exSnWYOeesO5Ryb/H5/Ovq+byrej5ftEBzBrVTXfcCe4D1Cy1jNX8ZcMUwnsM2nsvVwFer13w38KoFmvONwLeqdT4BPLeb/Xn5AUkqUMnn3CXp/y3LXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXo/wB2mxjbBW5IzgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_times_df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Above, it looks like it can take up to 1s to classify a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = get_date_suffix()\n",
    "df_class.to_csv(f'./classified_data/americanair_sample_{suffix}_sa_classified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_times_df.to_csv(f'./classification_times/americanair_{suffix}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [pandas create new column based on values from other columns / apply a function of multiple columns, row-wise](https://stackoverflow.com/a/46570641/3211335)\n",
    "* [Creating an empty Pandas DataFrame, then filling it?](https://stackoverflow.com/a/56746204/3211335)\n",
    "* [How to iterate over rows in a DataFrame in Pandas](https://stackoverflow.com/a/16476974/3211335)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db52a7dadfe31a2badaec6a7be7fb56ac8c6fe66c68473b9e453c86b55981548"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
