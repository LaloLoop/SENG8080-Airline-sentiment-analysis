{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live sentiment analysis - Demo day\n",
    "\n",
    "This notebook is the main entry point to run the live sentiment analysis by using the Twitter API and the dashboarding tools selected so far, as well as a messages broker to process the incoming Twitter data.\n",
    "\n",
    "The diagram below shows the overall architecture of the services to run.\n",
    "\n",
    "![Architecture diagram](./imgs/architecture.png \"General Architecture\")\n",
    "\n",
    "[Link to original diagram (read only)](https://drive.google.com/file/d/1Y2t8Xp8DRvXdSBzT_klcOaPPNTXBQkDd/view?usp=sharing)\n",
    "\n",
    "Major services will be hosted in the cloud with managed alternatives:\n",
    "\n",
    "* Kafka: Hosted by Confluent cloud under the free tier.\n",
    "* Elasticsearch: Hosted by Elastic under the free tier.\n",
    "\n",
    "Both hosted providers make the development easier by giving guidance on how to connect and setup clients for their respective platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python producer\n",
    "\n",
    "A Python producer was created with the [onboarding steps](https://docs.confluent.io/platform/current/tutorials/examples/clients/docs/python.html?utm_source=github&utm_medium=demo&utm_campaign=ch.examples_type.community_content.clients-ccloud) obtained in Confluent Cloud.\n",
    "\n",
    "> Special steps were followed to install the `confluent-kafka` python library in an M1 machine, see [this issue's comment](https://github.com/confluentinc/confluent-kafka-python/issues/1190#issuecomment-1195952767).\n",
    "\n",
    "Once the steps were followed in the above linked resources, the first messages were seen in Confluent cloud, these messages were not related to Twitter's data, but to simple integer messages.\n",
    "\n",
    "![Messages produced via CLI](./imgs/cli-sample-producer.png)\n",
    "\n",
    "The image above shows the CLI sample producer obtained from the Confluent Cloud setup page, it shows the application working properly with the installed dependencies. This base code will be employed to build the actual producer to send Tweet data into the topic.\n",
    "\n",
    "![Messages in Confluent](./imgs/confluent-messages.png \"Messages in confluent cloud\")\n",
    "\n",
    "The above image shows the produces messages in the Confluent Cloud UI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing Tweets\n",
    "\n",
    "By using the Twitter client seen during the Project update N. 2 ([notebook](./hugging-face.ipynb)) the code below retrieves sample tweet data and produces it into the Kafka client.\n",
    "\n",
    "The code below expects a configuration file to provide the Kafka provider with the right parameters to connect to the Confluent cluster. The `ccloud_lib` utilities file was borrowed from the original sample code from Confluent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer, KafkaError\n",
    "import ccloud_lib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseProducer:\n",
    "    \"\"\"Defines the basic connectivity to reach Kafka instance hosted in Confluent Cloud\"\"\"\n",
    "    def __init__(self, config_file, topic):\n",
    "        \"\"\"Creates a BaedProducer with the provided configuration and topic\n",
    "        \"\"\"\n",
    "\n",
    "        conf = ccloud_lib.read_ccloud_config(config_file)\n",
    "\n",
    "        producer_conf = ccloud_lib.pop_schema_registry_params_from_config(conf)\n",
    "        self.producer = Producer(producer_conf)\n",
    "\n",
    "        self.topic = topic\n",
    "        ccloud_lib.create_topic(conf, topic)\n",
    "\n",
    "        self.delivered_records = 0\n",
    "\n",
    "    def acked(self, err, msg):\n",
    "        \"\"\"Delivery report handler called on\n",
    "        successful or failed delivery of message\n",
    "        \"\"\"\n",
    "        if err is not None:\n",
    "            print(\"Failed to deliver message: {}\".format(err))\n",
    "        else:\n",
    "            self.delivered_records += 1\n",
    "            print(\"Produced record to topic {} partition [{}] @ offset {}\".format(msg.topic(), msg.partition(), msg.offset()))\n",
    "\n",
    "    def produce(self, values):\n",
    "        for v in values:\n",
    "            record_key = str(v['id'])\n",
    "            record_value = json.dumps(v)\n",
    "            \n",
    "            print(\"Producing record: {}: {}\".format(record_key, record_value))\n",
    "            \n",
    "            self.producer.produce(self.topic, key=record_key, value=record_value, on_delivery=self.acked)\n",
    "            # p.poll() serves delivery reports (on_delivery)\n",
    "            # from previous produce() calls.\n",
    "            self.producer.poll(0)\n",
    "\n",
    "        self.producer.flush()\n",
    "\n",
    "        print(\"{} messages were produced to topic {}!\".format(self.delivered_records, self.topic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, the `BaseProducer` needs to be somehow tested, so that it can be fixed in case we are not able to produce data. Let's start by loading some of the available sample data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(airline, filename, sample_size=10):\n",
    "    aircanada_df = pd.read_csv(filename)\n",
    "    aircanada_sample_df = aircanada_df.sample(sample_size)\n",
    "\n",
    "    for i in range(aircanada_sample_df.iloc[:, 1:].shape[0]):\n",
    "        row_json = aircanada_df.iloc[i, 1:].to_dict()\n",
    "        row_json['airline'] = airline\n",
    "        yield row_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = sample_data('aircanada', './fresh_data/aircanada_sample_07072022_210411.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1658885792.059|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property session.timeout.ms is a consumer property and will be ignored by this producer instance\n",
      "%4|1658885792.063|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property session.timeout.ms is a consumer property and will be ignored by this producer instance\n"
     ]
    }
   ],
   "source": [
    "producer = BaseProducer('./config.properties', 'twitter-data-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing record: 1545212028247220225: {\"created_at\": \"2022-07-08T01:03:50.000Z\", \"id\": 1545212028247220225, \"text\": \"RT @mcdowell_norm: @OmarAlghabra @AirCanada Best thing you can do is RESIGN!\", \"airline\": \"aircanada\"}\n",
      "Producing record: 1545212013227479040: {\"created_at\": \"2022-07-08T01:03:47.000Z\", \"id\": 1545212013227479040, \"text\": \"@OmarAlghabra @AirCanada End the masks. End the mandates. End the ArriveCAN app. Problem solved\", \"airline\": \"aircanada\"}\n",
      "Producing record: 1545211993564610561: {\"created_at\": \"2022-07-08T01:03:42.000Z\", \"id\": 1545211993564610561, \"text\": \"@OmarAlghabra @AirCanada Remember you recently said out -of-practice travellers  are causing delays at security checkpoints ?  I do\", \"airline\": \"aircanada\"}\n",
      "Producing record: 1545211956495130625: {\"created_at\": \"2022-07-08T01:03:33.000Z\", \"id\": 1545211956495130625, \"text\": \"@OmarAlghabra @AirCanada You have to return to the operations that were in place in 2019 and prior. Eliminate all mandates, apps, and restrictions. Offer an olive branch to all those employees you fired. More rules and regulations just cause delays. Everyone knows that and so should you.\", \"airline\": \"aircanada\"}\n",
      "Producing record: 1545211910630817792: {\"created_at\": \"2022-07-08T01:03:22.000Z\", \"id\": 1545211910630817792, \"text\": \"RT @SamS96095050: @AirCanada Hello Air Canada, i made a complaint on June 22 but no one have even replied. Could you please at least reply?\\u2026\", \"airline\": \"aircanada\"}\n",
      "Producing record: 1545211783363043332: {\"created_at\": \"2022-07-08T01:02:52.000Z\", \"id\": 1545211783363043332, \"text\": \"HOW CAN ANYONE GET A HOLD OF @AirCanada IF THEY DONT LET PEOPLE BE PUT ON HOLD? AC, your site says I have to call to change my flight but I can't get a hold of anyone! This is such a horrible set up. Please respond to my DM from June 15th!\", \"airline\": \"aircanada\"}\n",
      "Producing record: 1545211747312738304: {\"created_at\": \"2022-07-08T01:02:43.000Z\", \"id\": 1545211747312738304, \"text\": \"No progress or updates on my lost baggage still after 12 days and one visit to the airport. #AirCanada @AirCanada\", \"airline\": \"aircanada\"}\n",
      "Producing record: 1545211630820130819: {\"created_at\": \"2022-07-08T01:02:16.000Z\", \"id\": 1545211630820130819, \"text\": \"RT @Fernand55591815: Ayuda por favor. Mi hijo vuelve a EEUU via Canad\\u00e1 donde tiene 7 hs de escala, le dicen que necesita una visa, no puede\\u2026\", \"airline\": \"aircanada\"}\n",
      "Producing record: 1545211172651147265: {\"created_at\": \"2022-07-08T01:00:26.000Z\", \"id\": 1545211172651147265, \"text\": \"@ownbossmusic @AirCanada Poha man, foda isso\", \"airline\": \"aircanada\"}\n",
      "Producing record: 1545211107865935873: {\"created_at\": \"2022-07-08T01:00:11.000Z\", \"id\": 1545211107865935873, \"text\": \"RT @NiaVardalos: Hello @AirCanada and @aegeanairlines where are my family\\u2019s bags? Four days without five passengers\\u2019 bags. No clothes, no l\\u2026\", \"airline\": \"aircanada\"}\n",
      "Produced record to topic twitter-data-test partition [0] @ offset 10\n",
      "Produced record to topic twitter-data-test partition [0] @ offset 11\n",
      "Produced record to topic twitter-data-test partition [0] @ offset 12\n",
      "Produced record to topic twitter-data-test partition [0] @ offset 13\n",
      "Produced record to topic twitter-data-test partition [0] @ offset 14\n",
      "Produced record to topic twitter-data-test partition [0] @ offset 15\n",
      "Produced record to topic twitter-data-test partition [0] @ offset 16\n",
      "Produced record to topic twitter-data-test partition [0] @ offset 17\n",
      "Produced record to topic twitter-data-test partition [0] @ offset 18\n",
      "Produced record to topic twitter-data-test partition [0] @ offset 19\n",
      "10 messages were produced to topic twitter-data-test!\n"
     ]
    }
   ],
   "source": [
    "producer.produce(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above running we can see how the twitter data becomes available inside the Kafka Topic.\n",
    "\n",
    "![Twitter data Kafka test](./imgs/twitter-data-test.png \"Twitter Kafka test\")\n",
    "\n",
    "Now let's look at the consumer code to do the sentiment analysis while reading from the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets consumer\n",
    "\n",
    "This section of the notebook focuses on reading the topic and running the sentiment analysis of the data. Remembering how the result of the classification looks, provides an idea on what is the expected output to be inserted into the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircanada_class_df = pd.read_csv('./classified_data/aircanada_sample_07072022_210411_sa_classified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2022-07-08T00:14:38.000Z</td>\n",
       "      <td>1545199643503472640</td>\n",
       "      <td>@OmarAlghabra @AirCanada Resign you vermin</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.866527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2022-07-08T00:14:40.000Z</td>\n",
       "      <td>1545199654597525504</td>\n",
       "      <td>@OmarAlghabra @AirCanada if I sh1t the bed as ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.709690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2022-07-07T23:07:07.000Z</td>\n",
       "      <td>1545182652306665472</td>\n",
       "      <td>@OmarAlghabra @AirCanada @OmarAlghabra you nee...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.954575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2022-07-07T22:37:15.000Z</td>\n",
       "      <td>1545175137321816065</td>\n",
       "      <td>@mnakhleh @gkarstenssmith @AirCanada One name ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.931161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2022-07-07T22:36:06.000Z</td>\n",
       "      <td>1545174850582581249</td>\n",
       "      <td>@gkarstenssmith @AirCanada There are worse pla...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.874780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-07-08T00:56:35.000Z</td>\n",
       "      <td>1545210202487631872</td>\n",
       "      <td>RT @AmbArunSahu: Still waiting for update on m...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.792350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2022-07-07T22:37:49.000Z</td>\n",
       "      <td>1545175278841995264</td>\n",
       "      <td>Do you let customers take a properly packed pa...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.763792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-07-08T01:02:43.000Z</td>\n",
       "      <td>1545211747312738304</td>\n",
       "      <td>No progress or updates on my lost baggage stil...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.516521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-07-08T00:57:31.000Z</td>\n",
       "      <td>1545210437200793600</td>\n",
       "      <td>@OmarAlghabra @AirCanada Canceling flights is ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2022-07-07T22:09:11.000Z</td>\n",
       "      <td>1545168076664193027</td>\n",
       "      <td>@Fernand55591815 @AirCanada @AirCanadaLatAm La...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.836714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   created_at                   id  \\\n",
       "108  2022-07-08T00:14:38.000Z  1545199643503472640   \n",
       "107  2022-07-08T00:14:40.000Z  1545199654597525504   \n",
       "284  2022-07-07T23:07:07.000Z  1545182652306665472   \n",
       "341  2022-07-07T22:37:15.000Z  1545175137321816065   \n",
       "346  2022-07-07T22:36:06.000Z  1545174850582581249   \n",
       "15   2022-07-08T00:56:35.000Z  1545210202487631872   \n",
       "338  2022-07-07T22:37:49.000Z  1545175278841995264   \n",
       "6    2022-07-08T01:02:43.000Z  1545211747312738304   \n",
       "14   2022-07-08T00:57:31.000Z  1545210437200793600   \n",
       "386  2022-07-07T22:09:11.000Z  1545168076664193027   \n",
       "\n",
       "                                                  text classification  \\\n",
       "108         @OmarAlghabra @AirCanada Resign you vermin       Negative   \n",
       "107  @OmarAlghabra @AirCanada if I sh1t the bed as ...       Negative   \n",
       "284  @OmarAlghabra @AirCanada @OmarAlghabra you nee...       Negative   \n",
       "341  @mnakhleh @gkarstenssmith @AirCanada One name ...       Negative   \n",
       "346  @gkarstenssmith @AirCanada There are worse pla...       Negative   \n",
       "15   RT @AmbArunSahu: Still waiting for update on m...        Neutral   \n",
       "338  Do you let customers take a properly packed pa...        Neutral   \n",
       "6    No progress or updates on my lost baggage stil...        Neutral   \n",
       "14   @OmarAlghabra @AirCanada Canceling flights is ...       Negative   \n",
       "386  @Fernand55591815 @AirCanada @AirCanadaLatAm La...       Negative   \n",
       "\n",
       "        score  \n",
       "108  0.866527  \n",
       "107  0.709690  \n",
       "284  0.954575  \n",
       "341  0.931161  \n",
       "346  0.874780  \n",
       "15   0.792350  \n",
       "338  0.763792  \n",
       "6    0.516521  \n",
       "14   0.714646  \n",
       "386  0.836714  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aircanada_class_df.iloc[:, 1:].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add the code for the consumer to retrieve the data from Kafka, it's based on the code provided by Confluent to consume from their managed clusters.\n",
    "\n",
    "The consumer is executed in a similar fashion to the producer, the `config.properties` file can work for both of them.\n",
    "\n",
    "![Consumer CLI test](./imgs/cli-sample-consumer.png \"Sample Consumer\")\n",
    "\n",
    "The consumer will continue to poll from the topic until a keyboard interruption happens.\n",
    "\n",
    "The components needed to classify the tweets data are now ready, as the consumer will be able to pull the data and classify it to finally produce it into the new `tweets-data-classified`. The resulting schema will be the same as the original Tweets, but with a new set of properties named: `classification.sentiment` and `classification.score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardo@yalo.com/miniforge3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaClassifier:\n",
    "    def __init__(self):\n",
    "\n",
    "        model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "        self.classifier = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)\n",
    "\n",
    "    def classify(self, text):\n",
    "        rbt_result = self.classifier(text)[0]\n",
    "\n",
    "        return rbt_result\n",
    "\n",
    "class ClassifierConsumer:\n",
    "    def __init__(self, topic, output_topic, config_file):\n",
    "        self.topic = topic\n",
    "        self.output_topic = output_topic\n",
    "\n",
    "        self.total_count = 0\n",
    "        \n",
    "        # Dependency configuration\n",
    "        self.producer = BaseProducer(config_file, self.output_topic)\n",
    "        self.classifier = RobertaClassifier()\n",
    "\n",
    "        # Consumer configuration\n",
    "        conf = ccloud_lib.read_ccloud_config(config_file)\n",
    "\n",
    "        consumer_conf = ccloud_lib.pop_schema_registry_params_from_config(conf)\n",
    "\n",
    "        consumer_conf['group.id'] = 'notebook_classifier_cg'\n",
    "        consumer_conf['auto.offset.reset'] = 'earliest'\n",
    "\n",
    "        self.consumer = Consumer(consumer_conf)\n",
    "        self.consumer.subscribe([self.topic])\n",
    "\n",
    "    def consume(self):\n",
    "        try:\n",
    "            while True:\n",
    "                msg = self.consumer.poll(1.0)\n",
    "                if msg is None:\n",
    "                    # No message available within timeout.\n",
    "                    # Initial message consumption may take up to\n",
    "                    # `session.timeout.ms` for the consumer group to\n",
    "                    # rebalance and start consuming\n",
    "                    print(\"Waiting for message or event/error in poll()\")\n",
    "                    continue\n",
    "\n",
    "                elif msg.error():\n",
    "                    print('error: {}'.format(msg.error()))\n",
    "\n",
    "                else:\n",
    "                    # Check for Kafka message\n",
    "                    record_key = msg.key()\n",
    "                    record_value = msg.value()\n",
    "                    tweet_data = json.loads(record_value)\n",
    "\n",
    "                    class_result = self.classifier.classify(tweet_data['text'])\n",
    "                    sentiment = class_result['label']\n",
    "                    score = class_result['score']\n",
    "\n",
    "                    tweet_classified = {**tweet_data, 'classification': {'sentiment': sentiment, 'score': score}}\n",
    "                    \n",
    "                    self.producer.produce([tweet_classified])\n",
    "\n",
    "                    print(\"Consumed record with key {} and ID {}\".format(record_key, tweet_data['id']))\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "        finally:\n",
    "            # Leave group and commit final offsets\n",
    "            self.consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to launch the consumer, start by creating an instance and initialize all of its dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1658886030.954|CONFWARN|rdkafka#producer-9| [thrd:app]: Configuration property session.timeout.ms is a consumer property and will be ignored by this producer instance\n",
      "%4|1658886030.959|CONFWARN|rdkafka#producer-10| [thrd:app]: Configuration property session.timeout.ms is a consumer property and will be ignored by this producer instance\n",
      "All model checkpoint layers were used when initializing TFXLMRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFXLMRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "input_topic = 'twitter-data-test'\n",
    "output_topic = 'twitter-data-classified'\n",
    "\n",
    "sentiment_consumer = ClassifierConsumer(input_topic, output_topic, './config.properties')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the consumer and classifier are loaded, consumption can start so that we get the classified data into the output topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing record: 1545212028247220225: {\"created_at\": \"2022-07-08T01:03:50.000Z\", \"id\": 1545212028247220225, \"text\": \"RT @mcdowell_norm: @OmarAlghabra @AirCanada Best thing you can do is RESIGN!\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Neutral\", \"score\": 0.4647398293018341}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 0\n",
      "1 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545212028247220225' and ID 1545212028247220225\n",
      "Producing record: 1545212013227479040: {\"created_at\": \"2022-07-08T01:03:47.000Z\", \"id\": 1545212013227479040, \"text\": \"@OmarAlghabra @AirCanada End the masks. End the mandates. End the ArriveCAN app. Problem solved\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.6257174015045166}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 1\n",
      "2 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545212013227479040' and ID 1545212013227479040\n",
      "Producing record: 1545211993564610561: {\"created_at\": \"2022-07-08T01:03:42.000Z\", \"id\": 1545211993564610561, \"text\": \"@OmarAlghabra @AirCanada Remember you recently said out -of-practice travellers  are causing delays at security checkpoints ?  I do\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.7561778426170349}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 2\n",
      "3 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211993564610561' and ID 1545211993564610561\n",
      "Producing record: 1545211956495130625: {\"created_at\": \"2022-07-08T01:03:33.000Z\", \"id\": 1545211956495130625, \"text\": \"@OmarAlghabra @AirCanada You have to return to the operations that were in place in 2019 and prior. Eliminate all mandates, apps, and restrictions. Offer an olive branch to all those employees you fired. More rules and regulations just cause delays. Everyone knows that and so should you.\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.8212971091270447}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 3\n",
      "4 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211956495130625' and ID 1545211956495130625\n",
      "Producing record: 1545211910630817792: {\"created_at\": \"2022-07-08T01:03:22.000Z\", \"id\": 1545211910630817792, \"text\": \"RT @SamS96095050: @AirCanada Hello Air Canada, i made a complaint on June 22 but no one have even replied. Could you please at least reply?\\u2026\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Neutral\", \"score\": 0.5285728573799133}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 4\n",
      "5 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211910630817792' and ID 1545211910630817792\n",
      "Producing record: 1545211783363043332: {\"created_at\": \"2022-07-08T01:02:52.000Z\", \"id\": 1545211783363043332, \"text\": \"HOW CAN ANYONE GET A HOLD OF @AirCanada IF THEY DONT LET PEOPLE BE PUT ON HOLD? AC, your site says I have to call to change my flight but I can't get a hold of anyone! This is such a horrible set up. Please respond to my DM from June 15th!\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.9543615579605103}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 5\n",
      "6 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211783363043332' and ID 1545211783363043332\n",
      "Producing record: 1545211747312738304: {\"created_at\": \"2022-07-08T01:02:43.000Z\", \"id\": 1545211747312738304, \"text\": \"No progress or updates on my lost baggage still after 12 days and one visit to the airport. #AirCanada @AirCanada\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Neutral\", \"score\": 0.5165213346481323}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 6\n",
      "7 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211747312738304' and ID 1545211747312738304\n",
      "Producing record: 1545211630820130819: {\"created_at\": \"2022-07-08T01:02:16.000Z\", \"id\": 1545211630820130819, \"text\": \"RT @Fernand55591815: Ayuda por favor. Mi hijo vuelve a EEUU via Canad\\u00e1 donde tiene 7 hs de escala, le dicen que necesita una visa, no puede\\u2026\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.6527155637741089}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 7\n",
      "8 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211630820130819' and ID 1545211630820130819\n",
      "Producing record: 1545211172651147265: {\"created_at\": \"2022-07-08T01:00:26.000Z\", \"id\": 1545211172651147265, \"text\": \"@ownbossmusic @AirCanada Poha man, foda isso\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.9404411315917969}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 8\n",
      "9 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211172651147265' and ID 1545211172651147265\n",
      "Producing record: 1545211107865935873: {\"created_at\": \"2022-07-08T01:00:11.000Z\", \"id\": 1545211107865935873, \"text\": \"RT @NiaVardalos: Hello @AirCanada and @aegeanairlines where are my family\\u2019s bags? Four days without five passengers\\u2019 bags. No clothes, no l\\u2026\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.716509997844696}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 9\n",
      "10 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211107865935873' and ID 1545211107865935873\n",
      "Producing record: 1545212028247220225: {\"created_at\": \"2022-07-08T01:03:50.000Z\", \"id\": 1545212028247220225, \"text\": \"RT @mcdowell_norm: @OmarAlghabra @AirCanada Best thing you can do is RESIGN!\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Neutral\", \"score\": 0.4647398293018341}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 10\n",
      "11 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545212028247220225' and ID 1545212028247220225\n",
      "Producing record: 1545212013227479040: {\"created_at\": \"2022-07-08T01:03:47.000Z\", \"id\": 1545212013227479040, \"text\": \"@OmarAlghabra @AirCanada End the masks. End the mandates. End the ArriveCAN app. Problem solved\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.6257174015045166}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 11\n",
      "12 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545212013227479040' and ID 1545212013227479040\n",
      "Producing record: 1545211993564610561: {\"created_at\": \"2022-07-08T01:03:42.000Z\", \"id\": 1545211993564610561, \"text\": \"@OmarAlghabra @AirCanada Remember you recently said out -of-practice travellers  are causing delays at security checkpoints ?  I do\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.7561778426170349}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 12\n",
      "13 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211993564610561' and ID 1545211993564610561\n",
      "Producing record: 1545211956495130625: {\"created_at\": \"2022-07-08T01:03:33.000Z\", \"id\": 1545211956495130625, \"text\": \"@OmarAlghabra @AirCanada You have to return to the operations that were in place in 2019 and prior. Eliminate all mandates, apps, and restrictions. Offer an olive branch to all those employees you fired. More rules and regulations just cause delays. Everyone knows that and so should you.\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.8212971091270447}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 13\n",
      "14 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211956495130625' and ID 1545211956495130625\n",
      "Producing record: 1545211910630817792: {\"created_at\": \"2022-07-08T01:03:22.000Z\", \"id\": 1545211910630817792, \"text\": \"RT @SamS96095050: @AirCanada Hello Air Canada, i made a complaint on June 22 but no one have even replied. Could you please at least reply?\\u2026\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Neutral\", \"score\": 0.5285728573799133}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 14\n",
      "15 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211910630817792' and ID 1545211910630817792\n",
      "Producing record: 1545211783363043332: {\"created_at\": \"2022-07-08T01:02:52.000Z\", \"id\": 1545211783363043332, \"text\": \"HOW CAN ANYONE GET A HOLD OF @AirCanada IF THEY DONT LET PEOPLE BE PUT ON HOLD? AC, your site says I have to call to change my flight but I can't get a hold of anyone! This is such a horrible set up. Please respond to my DM from June 15th!\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.9543615579605103}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 15\n",
      "16 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211783363043332' and ID 1545211783363043332\n",
      "Producing record: 1545211747312738304: {\"created_at\": \"2022-07-08T01:02:43.000Z\", \"id\": 1545211747312738304, \"text\": \"No progress or updates on my lost baggage still after 12 days and one visit to the airport. #AirCanada @AirCanada\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Neutral\", \"score\": 0.5165213346481323}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 16\n",
      "17 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211747312738304' and ID 1545211747312738304\n",
      "Producing record: 1545211630820130819: {\"created_at\": \"2022-07-08T01:02:16.000Z\", \"id\": 1545211630820130819, \"text\": \"RT @Fernand55591815: Ayuda por favor. Mi hijo vuelve a EEUU via Canad\\u00e1 donde tiene 7 hs de escala, le dicen que necesita una visa, no puede\\u2026\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.6527155637741089}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 17\n",
      "18 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211630820130819' and ID 1545211630820130819\n",
      "Producing record: 1545211172651147265: {\"created_at\": \"2022-07-08T01:00:26.000Z\", \"id\": 1545211172651147265, \"text\": \"@ownbossmusic @AirCanada Poha man, foda isso\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.9404411315917969}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 18\n",
      "19 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211172651147265' and ID 1545211172651147265\n",
      "Producing record: 1545211107865935873: {\"created_at\": \"2022-07-08T01:00:11.000Z\", \"id\": 1545211107865935873, \"text\": \"RT @NiaVardalos: Hello @AirCanada and @aegeanairlines where are my family\\u2019s bags? Four days without five passengers\\u2019 bags. No clothes, no l\\u2026\", \"airline\": \"aircanada\", \"classification\": {\"sentiment\": \"Negative\", \"score\": 0.716509997844696}}\n",
      "Produced record to topic twitter-data-classified partition [0] @ offset 19\n",
      "20 messages were produced to topic twitter-data-classified!\n",
      "Consumed record with key b'1545211107865935873' and ID 1545211107865935873\n",
      "Waiting for message or event/error in poll()\n",
      "Waiting for message or event/error in poll()\n",
      "Waiting for message or event/error in poll()\n",
      "Waiting for message or event/error in poll()\n",
      "Waiting for message or event/error in poll()\n"
     ]
    }
   ],
   "source": [
    "sentiment_consumer.consume()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification was executed successfully from the data available in the topics. The output from the above run can be seen in the image below for historical purposes (i.e. the output being random as we test this).\n",
    "\n",
    "![Notebook Classifier Consumer](./imgs/notebook-classifier-consumer.png \"Notebook Classifier\")\n",
    "\n",
    "The produced messages can be found also in Confluent Cloud where the classified data is now available in the topic, ready to be ingested by Elastic Search.\n",
    "\n",
    "![Classified messages in Confluent Cloud](./imgs/confluent-cloud-classified-messages.png \"Confluent Cloud Classified\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Search ingestion\n",
    "\n",
    "Now that the data is available in Confluent Cloud, an Elasticsearch connector is also available to send the data there,and start making use of it. To better understand how to write data into Elasticsearch, the sample code provided by the hosting provider is executed below.\n",
    "\n",
    "The tutorial followed can be found in [this official docs page](https://www.elastic.co/guide/en/cloud/current/ec-getting-started-python.html#ec_output).\n",
    "\n",
    "> There was an option to use the Kafka/Confluent Sink connector, but it's just too expensive at ~0.11c/hour (80 USD a month), thus, the code below was implemented to write the classified topic data into Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import configparser\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hint: The username and password were downloaded when the cluster / deployment was being created, look for a csv you might have downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id_file = './elastic-cluster-id.config'\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('elastic.ini')\n",
    "\n",
    "es = Elasticsearch(\n",
    "    cloud_id=config['ELASTIC']['cloud_id'],\n",
    "    basic_auth=(config['ELASTIC']['user'], config['ELASTIC']['password'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'instance-0000000000', 'cluster_name': 'b7714844d7944f16bda41a67ea8e360e', 'cluster_uuid': 'WE73ImPFSsqnC29i0CIKsA', 'version': {'number': '8.3.2', 'build_type': 'docker', 'build_hash': '8b0b1f23fbebecc3c88e4464319dea8989f374fd', 'build_date': '2022-07-06T15:15:15.901688194Z', 'build_snapshot': False, 'lucene_version': '9.2.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now write some data into Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_index': 'star-wars', '_id': 'nQzJPYIB0FznHg1U0cfV', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.index(\n",
    " index='star-wars',\n",
    " document={\n",
    "  'character': 'Han Solo',\n",
    "  'quote': 'I know'\n",
    " })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_index': 'star-wars', '_id': 'FCvKPYIB4tvjElvWuRD4', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 1, '_primary_term': 1})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.index(\n",
    " index='star-wars',\n",
    " document={\n",
    "  'character': 'Storm Trooper',\n",
    "  'quote': 'Get them... AaaAAaaAAAaahh!'\n",
    " })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_index': 'star-wars', '_id': 'ngzLPYIB0FznHg1UlcdB', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 2, '_primary_term': 1})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.index(\n",
    " index='star-wars',\n",
    " document={\n",
    "  'character': 'Obi Wan Kenobi',\n",
    "  'quote': \"That's a name I haven't heard in a long time\"\n",
    " })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refresh the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_shards': {'total': 2, 'successful': 2, 'failed': 0}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.refresh(index='star-wars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'star-wars',\n",
       "  '_id': 'nQzJPYIB0FznHg1U0cfV',\n",
       "  '_score': 0.62289643,\n",
       "  '_source': {'character': 'Han Solo', 'quote': 'I know'}},\n",
       " {'_index': 'star-wars',\n",
       "  '_id': 'ngzLPYIB0FznHg1UlcdB',\n",
       "  '_score': 0.333551,\n",
       "  '_source': {'character': 'Obi Wan Kenobi',\n",
       "   'quote': \"That's a name I haven't heard in a long time\"}}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = es.search(\n",
    " index='star-wars',\n",
    "  query={\n",
    "    'match': {'quote': 'I'}\n",
    "  }\n",
    " )\n",
    "\n",
    "result['hits']['hits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got a hold of what the Elasticsearch python client can do, it's time to write the Consumer that will actually send the data to Elasticsearch by reading the classified information from Kafka."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch simple Sink\n",
    "\n",
    "The code below puts together the knowledge we've already gathered about how to consume data from Confluent and send it to Elasticsearch as shown above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticClient:\n",
    "    def __init__(self, index_name, config_file):\n",
    "        self.index_name = index_name\n",
    "\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(config_file)\n",
    "\n",
    "        self.es = Elasticsearch(\n",
    "            cloud_id=config['ELASTIC']['cloud_id'],\n",
    "            basic_auth=(config['ELASTIC']['user'], config['ELASTIC']['password'])\n",
    "        )\n",
    "\n",
    "        self.es.info()\n",
    "\n",
    "    def add_to_index(self, document: dict):\n",
    "        result = self.es.index(\n",
    "            index=self.index_name,\n",
    "            document=document\n",
    "        )\n",
    "\n",
    "        self.es.indices.refresh(index=self.index_name)\n",
    "\n",
    "        return result\n",
    "        \n",
    "\n",
    "class BaseConsumer:\n",
    "    \"\"\"Generalization to read Tweets data from any provided topic\"\"\"\n",
    "    def __init__(self, topic, config_file, consumer_name):\n",
    "        self.topic = topic\n",
    "\n",
    "        # Consumer configuration\n",
    "        conf = ccloud_lib.read_ccloud_config(config_file)\n",
    "\n",
    "        consumer_conf = ccloud_lib.pop_schema_registry_params_from_config(conf)\n",
    "\n",
    "        consumer_conf['group.id'] = consumer_name\n",
    "        consumer_conf['auto.offset.reset'] = 'earliest'\n",
    "\n",
    "        self.consumer = Consumer(consumer_conf)\n",
    "        self.consumer.subscribe([self.topic])\n",
    "\n",
    "    def consume(self):\n",
    "        try:\n",
    "            while True:\n",
    "                msg = self.consumer.poll(1.0)\n",
    "                if msg is None:\n",
    "                    # No message available within timeout.\n",
    "                    # Initial message consumption may take up to\n",
    "                    # `session.timeout.ms` for the consumer group to\n",
    "                    # rebalance and start consuming\n",
    "                    print(\"Waiting for message or event/error in poll()\")\n",
    "                    continue\n",
    "\n",
    "                elif msg.error():\n",
    "                    print('error: {}'.format(msg.error()))\n",
    "\n",
    "                else:\n",
    "                    # Check for Kafka message\n",
    "                    record_key = msg.key()\n",
    "                    record_value = msg.value()\n",
    "                    tweet_data = json.loads(record_value)\n",
    "\n",
    "                    yield tweet_data\n",
    "\n",
    "                    print(\"Consumed record with key {} and ID {}\".format(record_key, tweet_data['id']))\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "        finally:\n",
    "            # Leave group and commit final offsets\n",
    "            self.consumer.close()\n",
    "\n",
    "class ElasticSink:\n",
    "    def __init__(self, consumer: BaseConsumer, elastic_client: ElasticClient):\n",
    "        self.consumer = consumer\n",
    "        self.es = elastic_client\n",
    "\n",
    "    def sink(self):\n",
    "        for t in self.consumer.consume():\n",
    "            self.es.add_to_index(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = BaseConsumer('twitter-data-classified', './config.properties', 'notebook_elastic_cg')\n",
    "es = ElasticClient('airline-sentiment-analysis-test', './elastic.ini')\n",
    "\n",
    "sink = ElasticSink(consumer, es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumed record with key b'1545212013227479040' and ID 1545212013227479040\n",
      "Consumed record with key b'1545211993564610561' and ID 1545211993564610561\n",
      "Consumed record with key b'1545211956495130625' and ID 1545211956495130625\n",
      "Consumed record with key b'1545211910630817792' and ID 1545211910630817792\n",
      "Consumed record with key b'1545211783363043332' and ID 1545211783363043332\n",
      "Consumed record with key b'1545211747312738304' and ID 1545211747312738304\n",
      "Consumed record with key b'1545211630820130819' and ID 1545211630820130819\n",
      "Consumed record with key b'1545211172651147265' and ID 1545211172651147265\n",
      "Consumed record with key b'1545211107865935873' and ID 1545211107865935873\n",
      "Consumed record with key b'1545212028247220225' and ID 1545212028247220225\n",
      "Consumed record with key b'1545212013227479040' and ID 1545212013227479040\n",
      "Consumed record with key b'1545211993564610561' and ID 1545211993564610561\n",
      "Consumed record with key b'1545211956495130625' and ID 1545211956495130625\n",
      "Consumed record with key b'1545211910630817792' and ID 1545211910630817792\n",
      "Consumed record with key b'1545211783363043332' and ID 1545211783363043332\n",
      "Consumed record with key b'1545211747312738304' and ID 1545211747312738304\n",
      "Consumed record with key b'1545211630820130819' and ID 1545211630820130819\n",
      "Consumed record with key b'1545211172651147265' and ID 1545211172651147265\n",
      "Consumed record with key b'1545211107865935873' and ID 1545211107865935873\n",
      "Waiting for message or event/error in poll()\n",
      "Waiting for message or event/error in poll()\n",
      "Waiting for message or event/error in poll()\n",
      "Waiting for message or event/error in poll()\n",
      "Waiting for message or event/error in poll()\n"
     ]
    }
   ],
   "source": [
    "sink.sink()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db52a7dadfe31a2badaec6a7be7fb56ac8c6fe66c68473b9e453c86b55981548"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
